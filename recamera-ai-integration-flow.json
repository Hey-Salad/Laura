[
  {
    "id": "ai_integration_tab",
    "type": "tab",
    "label": "HeySalad AI Integration",
    "disabled": false,
    "info": "OpenAI Realtime + ElevenLabs + Gimbal Control"
  },
  {
    "id": "config_inject",
    "type": "inject",
    "z": "ai_integration_tab",
    "name": "Initialize AI Config",
    "props": [],
    "repeat": "",
    "crontab": "",
    "once": true,
    "onceDelay": 0.1,
    "x": 140,
    "y": 60,
    "wires": [["set_ai_config"]]
  },
  {
    "id": "set_ai_config",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Set AI Configuration",
    "func": "// Laura API Configuration\nflow.set('CAMERA_ID', '34236c48-2dae-4fe6-9bae-27e640f84d71');\nflow.set('LAURA_API_URL', 'https://laura.heysalad.app');\n\n// Get OpenAI credentials from Laura\n// You'll need to make an HTTP request to get the WebSocket URL and key\nflow.set('OPENAI_MODEL', 'gpt-4o-realtime-preview-2024-10-01');\n\n// ElevenLabs configuration\nflow.set('ELEVENLABS_VOICE_ID', '21m00Tcm4TlvDq8ikWAM'); // Rachel voice\n\nnode.warn('ðŸ¤– AI configuration initialized');\nnode.status({ fill: 'green', shape: 'dot', text: 'AI Ready' });\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 370,
    "y": 60,
    "wires": [["get_openai_creds"]]
  },
  {
    "id": "get_openai_creds",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Get OpenAI Credentials",
    "func": "const cameraId = flow.get('CAMERA_ID');\nconst lauraUrl = flow.get('LAURA_API_URL');\n\nmsg.url = `${lauraUrl}/api/ai/openai-realtime`;\nmsg.method = 'POST';\nmsg.payload = { camera_id: cameraId };\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 630,
    "y": 60,
    "wires": [["http_get_creds"]]
  },
  {
    "id": "http_get_creds",
    "type": "http request",
    "z": "ai_integration_tab",
    "name": "HTTP Get Credentials",
    "method": "use",
    "ret": "obj",
    "paytoqs": "ignore",
    "url": "",
    "tls": "",
    "persist": false,
    "proxy": "",
    "authType": "",
    "senderr": false,
    "x": 870,
    "y": 60,
    "wires": [["store_creds"]]
  },
  {
    "id": "store_creds",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Store Credentials",
    "func": "const response = msg.payload;\n\nif (response.websocket_url) {\n    flow.set('OPENAI_WS_URL', response.websocket_url);\n    node.warn('âœ… Secure WebSocket proxy configured');\n    node.warn('ðŸ“ WebSocket URL (with token): ' + response.websocket_url);\n    node.warn('ðŸŽ¯ COPY THIS URL TO WEBSOCKET CLIENT CONFIG');\n} else {\n    node.warn('âš ï¸ Failed to configure secure proxy');\n    node.error('Response: ' + JSON.stringify(response));\n}\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 1100,
    "y": 60,
    "wires": [[]]
  },
  {
    "id": "camera_capture",
    "type": "camera",
    "z": "ai_integration_tab",
    "option": 0,
    "audio": true,
    "volume": 80,
    "name": "Camera + Audio Capture",
    "x": 180,
    "y": 180,
    "wires": [["ai_inference", "stream_output"]]
  },
  {
    "id": "ai_inference",
    "type": "model",
    "z": "ai_integration_tab",
    "name": "AI Object Detection",
    "uri": "",
    "model": "",
    "tscore": 0.45,
    "tiou": 0.25,
    "debug": false,
    "trace": false,
    "counting": false,
    "classes": "",
    "splitter": "0,0,0,0",
    "x": 420,
    "y": 180,
    "wires": [["process_detections"]]
  },
  {
    "id": "process_detections",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Process Detections",
    "func": "// Process AI detections and trigger actions\nconst detections = msg.payload;\n\nif (detections && detections.length > 0) {\n    node.warn(`ðŸŽ¯ Detected ${detections.length} object(s)`);\n    \n    // Send to OpenAI for analysis\n    msg.detected_objects = detections;\n    msg.action = 'analyze_scene';\n    \n    return msg;\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "x": 660,
    "y": 180,
    "wires": [["send_to_openai"]]
  },
  {
    "id": "send_to_openai",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Format for OpenAI",
    "func": "// Format message for OpenAI Realtime API\nconst detections = msg.detected_objects || [];\nconst objectList = detections.map(d => d.class).join(', ');\n\nmsg.payload = {\n    type: 'conversation.item.create',\n    item: {\n        type: 'message',\n        role: 'user',\n        content: [{\n            type: 'input_text',\n            text: `I see the following objects in the kitchen: ${objectList}. What should I do?`\n        }]\n    }\n};\n\nnode.warn('ðŸ“¤ Sending to OpenAI:', msg.payload.item.content[0].text);\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 900,
    "y": 180,
    "wires": [["openai_websocket_out"]]
  },
  {
    "id": "openai_websocket_out",
    "type": "websocket out",
    "z": "ai_integration_tab",
    "name": "OpenAI WebSocket Out",
    "server": "openai_ws_server",
    "client": "openai_ws_client",
    "x": 180,
    "y": 280,
    "wires": []
  },
  {
    "id": "openai_websocket_in",
    "type": "websocket in",
    "z": "ai_integration_tab",
    "name": "OpenAI WebSocket In",
    "server": "openai_ws_server",
    "client": "openai_ws_client",
    "x": 180,
    "y": 360,
    "wires": [["process_openai_response"]]
  },
  {
    "id": "process_openai_response",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Process OpenAI Response",
    "func": "const response = msg.payload;\n\nif (typeof response === 'string') {\n    try {\n        msg.payload = JSON.parse(response);\n    } catch (e) {\n        // Already parsed\n    }\n}\n\nconst event = msg.payload;\n\nif (event.type === 'response.done' && event.response) {\n    const output = event.response.output;\n    if (output && output.length > 0) {\n        const textContent = output.find(o => o.type === 'text');\n        if (textContent && textContent.text) {\n            msg.ai_response = textContent.text;\n            node.warn('ðŸ¤– OpenAI:', textContent.text);\n            return msg;\n        }\n    }\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "x": 450,
    "y": 360,
    "wires": [["send_to_elevenlabs", "execute_gimbal_action"]]
  },
  {
    "id": "send_to_elevenlabs",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Send to ElevenLabs",
    "func": "const cameraId = flow.get('CAMERA_ID');\nconst lauraUrl = flow.get('LAURA_API_URL');\nconst voiceId = flow.get('ELEVENLABS_VOICE_ID');\n\nconst text = msg.ai_response;\n\nif (!text) {\n    return null;\n}\n\nmsg.url = `${lauraUrl}/api/ai/elevenlabs`;\nmsg.method = 'POST';\nmsg.payload = {\n    text: text,\n    voice_id: voiceId,\n    camera_id: cameraId\n};\n\nnode.warn('ðŸ”Š Generating speech:', text);\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 730,
    "y": 360,
    "wires": [["http_tts"]]
  },
  {
    "id": "http_tts",
    "type": "http request",
    "z": "ai_integration_tab",
    "name": "HTTP TTS Request",
    "method": "use",
    "ret": "bin",
    "paytoqs": "ignore",
    "url": "",
    "tls": "",
    "persist": false,
    "proxy": "",
    "authType": "",
    "senderr": false,
    "x": 970,
    "y": 360,
    "wires": [["play_audio"]]
  },
  {
    "id": "play_audio",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Play Audio on Speaker",
    "func": "// Audio buffer is in msg.payload\n// TODO: Play audio through reCamera speaker\n// This requires audio output node or exec command\n\nnode.warn('ðŸ”Š Audio received, size:', msg.payload.length, 'bytes');\n\n// Example: Save to temp file and play\nmsg.filename = '/tmp/tts_response.mp3';\nmsg.play_command = 'aplay /tmp/tts_response.mp3';\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 180,
    "y": 460,
    "wires": [["audio_output"]]
  },
  {
    "id": "audio_output",
    "type": "exec",
    "z": "ai_integration_tab",
    "command": "aplay /tmp/tts_response.mp3",
    "addpay": "",
    "append": "",
    "useSpawn": "false",
    "timer": "",
    "winHide": false,
    "oldrc": false,
    "name": "Play Audio Exec",
    "x": 430,
    "y": 460,
    "wires": [[], [], []]
  },
  {
    "id": "execute_gimbal_action",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Parse Gimbal Action",
    "func": "// Parse AI response for gimbal commands\nconst response = msg.ai_response.toLowerCase();\n\nlet gimbalCommand = null;\n\nif (response.includes('look left')) {\n    gimbalCommand = { preset: 'left' };\n} else if (response.includes('look right')) {\n    gimbalCommand = { preset: 'right' };\n} else if (response.includes('look up')) {\n    gimbalCommand = { preset: 'up' };\n} else if (response.includes('look down')) {\n    gimbalCommand = { preset: 'down' };\n} else if (response.includes('center') || response.includes('straight')) {\n    gimbalCommand = { preset: 'center' };\n}\n\nif (gimbalCommand) {\n    msg.gimbal_command = gimbalCommand;\n    node.warn('ðŸŽ® Gimbal command:', gimbalCommand);\n    return msg;\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "x": 740,
    "y": 460,
    "wires": [["send_gimbal_command"]]
  },
  {
    "id": "send_gimbal_command",
    "type": "function",
    "z": "ai_integration_tab",
    "name": "Send to Laura",
    "func": "const cameraId = flow.get('CAMERA_ID');\nconst lauraUrl = flow.get('LAURA_API_URL');\nconst gimbalCmd = msg.gimbal_command;\n\nmsg.url = `${lauraUrl}/api/cameras/${cameraId}/command`;\nmsg.method = 'POST';\nmsg.payload = {\n    command_type: 'gimbal_preset',\n    payload: gimbalCmd\n};\n\nnode.warn('ðŸ“¡ Sending gimbal command to Laura');\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "x": 990,
    "y": 460,
    "wires": [["http_gimbal"]]
  },
  {
    "id": "http_gimbal",
    "type": "http request",
    "z": "ai_integration_tab",
    "name": "HTTP Gimbal Command",
    "method": "use",
    "ret": "obj",
    "paytoqs": "ignore",
    "url": "",
    "tls": "",
    "persist": false,
    "proxy": "",
    "authType": "",
    "senderr": false,
    "x": 1220,
    "y": 460,
    "wires": [[]]
  },
  {
    "id": "stream_output",
    "type": "stream",
    "z": "ai_integration_tab",
    "name": "RTSP Stream",
    "protocol": 0,
    "port": 554,
    "session": "live",
    "username": "admin",
    "password": "admin",
    "x": 430,
    "y": 100,
    "wires": []
  },
  {
    "id": "manual_trigger",
    "type": "inject",
    "z": "ai_integration_tab",
    "name": "Test: Ask AI",
    "props": [
      {
        "p": "payload"
      }
    ],
    "repeat": "",
    "crontab": "",
    "once": false,
    "onceDelay": 0.1,
    "topic": "",
    "payload": "{\"detected_objects\":[{\"class\":\"person\"},{\"class\":\"pizza\"}]}",
    "payloadType": "json",
    "x": 140,
    "y": 560,
    "wires": [["process_detections"]]
  },
  {
    "id": "test_tts",
    "type": "inject",
    "z": "ai_integration_tab",
    "name": "Test: TTS",
    "props": [
      {
        "p": "ai_response",
        "v": "Hello from HeySalad! The kitchen looks great today.",
        "vt": "str"
      }
    ],
    "repeat": "",
    "crontab": "",
    "once": false,
    "onceDelay": 0.1,
    "x": 530,
    "y": 560,
    "wires": [["send_to_elevenlabs"]]
  },
  {
    "id": "test_gimbal",
    "type": "inject",
    "z": "ai_integration_tab",
    "name": "Test: Gimbal Left",
    "props": [
      {
        "p": "gimbal_command",
        "v": "{\"preset\":\"left\"}",
        "vt": "json"
      }
    ],
    "repeat": "",
    "crontab": "",
    "once": false,
    "onceDelay": 0.1,
    "x": 780,
    "y": 560,
    "wires": [["send_gimbal_command"]]
  },
  {
    "id": "debug_output",
    "type": "debug",
    "z": "ai_integration_tab",
    "name": "Debug Output",
    "active": true,
    "tosidebar": true,
    "console": false,
    "tostatus": false,
    "complete": "true",
    "targetType": "full",
    "statusVal": "",
    "statusType": "auto",
    "x": 660,
    "y": 100,
    "wires": []
  },
  {
    "id": "openai_ws_client",
    "type": "websocket-client",
    "path": "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01",
    "tls": "",
    "wholemsg": "true",
    "hb": "0",
    "subprotocol": "realtime"
  }
]
